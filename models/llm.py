from typing import Callable, List
import time

from langchain.chat_models import ChatOpenAI
from langchain.schema import ChatMessage
import openai


# client = openai.OpenAI(
#     # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
#     api_key="sk-a3b1a801d70747a0b7d3b2797a14ab05",
#     base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
# )

def replace_invalid_roles(messages):
    """
    æ‰¹é‡æ›¿æ¢messagesä¸­çš„éæ³•è§’è‰²åï¼š
    - human â†’ userï¼ˆç”¨æˆ·è§’è‰²ï¼‰
    - ai â†’ assistantï¼ˆåŠ©æ‰‹/AIè§’è‰²ï¼‰
    æ”¯æŒåµŒå¥—ç»“æ„ï¼Œæ·±æ‹·è´ä¿æŠ¤åŸæ•°æ®
    
    Args:
        messages (list): åŸå§‹æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å«"role"é”®çš„å­—å…¸
    
    Returns:
        list: æ›¿æ¢åçš„åˆæ³•æ¶ˆæ¯åˆ—è¡¨
    """
    import copy
    processed_messages = copy.deepcopy(messages)
    
    # å®šä¹‰éæ³•è§’è‰²åˆ°åˆæ³•è§’è‰²çš„æ˜ å°„
    role_mapping = {
        "human": "user",    # äººç±»æé—®è€… â†’ user
        "ai": "assistant"   # AIå›å¤è€… â†’ assistant
    }
    
    for msg in processed_messages:
        # ä»…å¤„ç†å­—å…¸ç±»å‹ä¸”åŒ…å«roleå­—æ®µçš„å…ƒç´ 
        if isinstance(msg, dict) and "role" in msg:
            # å¦‚æœå½“å‰roleåœ¨æ˜ å°„è¡¨ä¸­ï¼Œæ›¿æ¢ä¸ºåˆæ³•å€¼
            if msg["role"] in role_mapping:
                msg["role"] = role_mapping[msg["role"]]
    
    return processed_messages
def generate_one_completion(messages):
    openai.api_key = "sk-a3b1a801d70747a0b7d3b2797a14ab05"
    openai.api_base = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    messages = replace_invalid_roles(messages)
    # completion = client.chat.completions.create(
    completion = openai.ChatCompletion.create(
        model="qwen-flash",  # ä¿®æ­£ï¼šæ¨¡å‹åæ”¹ä¸ºå®˜æ–¹å…¼å®¹ç‰ˆ
        messages=messages,
        temperature=0.7,  # æ–°å¢ï¼šå¯é€‰ï¼Œæ§åˆ¶å›å¤éšæœºæ€§
        max_tokens=1024,   # æ–°å¢ï¼šå¯é€‰ï¼Œé™åˆ¶å›å¤é•¿åº¦
        headers={
            "Authorization": f"Bearer {openai.api_key}",
            "Content-Type": "application/json"
        }
    )
    # print(f"\nğŸ”¹ Generating for task: {task_id}")
    # ä¿®æ­£ï¼šç›´æ¥å–å±æ€§ï¼Œè€Œéè½¬JSONå­—ç¬¦ä¸²ï¼ˆæ›´é«˜æ•ˆï¼‰
    return completion.choices[0].message.content

class GPTWrapper:
    def __init__(self, llm_name: str, openai_api_key: str, long_ver: bool):
        self.model_name = llm_name
        self.openai_api_key = openai_api_key
        if long_ver:
            # llm_name = '3.5-turbo-16k'
            # llm_name = 'gpt-3.5-turbo'
            llm_name = 'gpt-4o'
        self.llm = ChatOpenAI(
            model=llm_name,
            temperature=0.0,
            openai_api_key=openai_api_key,
        )

    def __call__(self, messages: List[dict], stop: List[str] = [], replace_newline: bool = True) -> str:
        kwargs = {}
        if stop != []:
            kwargs['stop'] = stop
        for i in range(6):
            try:
                # output = self.llm(messages, **kwargs).content.strip('\n').strip()
                # output = chatanywhere_llm(messages, self.openai_api_key)
                output = generate_one_completion(messages)
                if output == "":  # APIè°ƒç”¨å¤±è´¥
                    print(f'\nAPI call failed, retrying {i+1}/6...')
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                output = output.strip('\n').strip()
                break
            except openai.error.RateLimitError:
                print(f'\nRate limit error, retrying {i+1}/6...')
                time.sleep(2)
        else:
            raise RuntimeError('Failed to generate response after 6 attempts')

        if replace_newline:
            output = output.replace('\n', '')
        return output

def LLM_CLS(llm_name: str, openai_api_key: str, long_ver: bool) -> Callable:
    if 'gpt' in llm_name:
        return GPTWrapper(llm_name, openai_api_key, long_ver)
    else:
        raise ValueError(f"Unknown LLM model name: {llm_name}")

def get_message(messages: List[dict]) -> List[dict]:
    final_messages = []
    # éå†æ¯ä¸ªdictæ¶ˆæ¯ï¼Œè½¬æ¢roleå’Œcontent
    # print(messages)
    for msg in messages:
        # æå–æ ¸å¿ƒå±æ€§ï¼šmsg['role']ï¼ˆè§’è‰²ï¼‰ã€msg['content']ï¼ˆæ¶ˆæ¯å†…å®¹ï¼‰
        role_map = {
            "human": "user",
            "ai": "assistant",
            "system": "system",
            "function": "function"
        }
        # è½¬æ¢è§’è‰²åç§°ä¸ºOpenAI APIæ ‡å‡†æ ¼å¼
        role_name = role_map.get(msg.get('role', 'user'), msg.get('role', 'user'))
        message = {
            "role": role_name,
            "content": msg.get('content', ''),
        }
        # æ‹¼æ¥å•æ¡æ¶ˆæ¯ï¼ˆæ ¼å¼å¯è‡ªå®šä¹‰ï¼Œä¿è¯ä¸Šä¸‹æ–‡æ¸…æ™°å³å¯ï¼‰
        final_messages.append(message)
    return final_messages

def chatanywhere_llm(messages: List[dict], openai_api_key: str) -> str:
    import http.client
    import json
    conn = http.client.HTTPSConnection("api.chatanywhere.tech")
    messages = get_message(messages)
    payload = json.dumps({
        "model": "gpt-3.5-turbo",
        "messages": messages
    })
    headers = {
        'Authorization': 'Bearer ' + openai_api_key,
        'Content-Type': 'application/json'
    }
    try:
        conn.request("POST", "/v1/chat/completions", payload, headers)
        res = conn.getresponse()
        data = res.read()
        answer = json.loads(data.decode("utf-8"))
        
        # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«é”™è¯¯
        if 'error' in answer:
            print(f"\nâŒ API Error: {answer['error']}")
            return ""
        
        # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«choices
        if 'choices' not in answer:
            print(f"\nâŒ Unexpected Response Format: {answer}")
            return ""
        
        return answer['choices'][0]['message']['content']
    except KeyError as e:
        # é”®é”™è¯¯ï¼Œæ‰“å°å®Œæ•´å“åº”ä»¥ä¾¿è°ƒè¯•
        print(f"\nâŒ KeyError: {str(e)}")
        print(f"Response: {answer if 'answer' in locals() else 'No response'}")
        return ""
    except json.JSONDecodeError as e:
        # JSONè§£æé”™è¯¯
        print(f"\nâŒ JSON Decode Error: {str(e)}")
        print(f"Raw data: {data.decode('utf-8') if 'data' in locals() else 'No data'}")
        return ""
    except Exception as e:
        # æ•è·æ‰€æœ‰å…¶ä»–æœªé¢„æœŸå¼‚å¸¸ï¼ˆå…œåº•ï¼Œé˜²æ­¢ç¨‹åºä¸­æ–­ï¼‰
        print(f"\nâŒ Unexpected Error: {str(e)}")
        return ""